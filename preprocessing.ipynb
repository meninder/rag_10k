{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.doc_processor_helper import get_all_data_paths, get_sub_documents\n",
    "from src.embedding_helper import EmbeddingHelper\n",
    "from src.opensearch import OpenSearchClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Data\n",
    "path_pdfs = get_all_data_paths()\n",
    "path_pdf = path_pdfs[2]\n",
    "sub_documents = get_sub_documents(path_pdf, chunk_size=1250, chunk_overlap=100)\n",
    "sub_documents = ['passage: '+ sd.page_content for sd in sub_documents]\n",
    "sub_documents = sub_documents[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Embeddings\n",
    "model_id='intfloat/e5-small-v2' # this model needs \"passge\" and \"query\" prepended to the text\n",
    "eh = EmbeddingHelper(model_id=model_id)\n",
    "embeddings_list = eh.get_embeddings_batch(sub_documents, chunk_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to OpenSearch\n",
    "osc = OpenSearchClient(model_id=model_id)\n",
    "osc.create_index(overwrite=True)\n",
    "osc.index_documents(embeddings_list, sub_documents, filename=path_pdf.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def write_embeddings(model_id:str, path_pdf:Path, osc:OpenSearchClient, prepend:bool):\n",
    "    sub_documents = get_sub_documents(path_pdf, chunk_size=1250, chunk_overlap=100)\n",
    "    if prepend:\n",
    "        sub_documents = ['passage: '+ sd.page_content for sd in sub_documents]\n",
    "    else:\n",
    "        sub_documents = [sd.page_content for sd in sub_documents]\n",
    "    sub_documents = sub_documents[:300]\n",
    "    eh = EmbeddingHelper(model_id=model_id)\n",
    "    embeddings_list = eh.get_embeddings_batch(sub_documents, chunk_size=10)\n",
    "    assert len(sub_documents)==len(embeddings_list), 'lengths do not match for '+str(path_pdf)\n",
    "    osc.index_documents(embeddings_list, sub_documents, filename=path_pdf.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:24:42,484 - src.logger - INFO - found 5 pdfs in /Users/meninderpurewal/My Drive/Mikey/Code/Retrieval/data\n",
      "2023-09-05 21:24:42,569 - src.logger - INFO - {'name': '87fee34ad386', 'cluster_name': 'docker-cluster', 'cluster_uuid': '-a_peNY5SsWnBbMYhkB_OA', 'version': {'distribution': 'opensearch', 'number': '2.6.0', 'build_type': 'tar', 'build_hash': '7203a5af21a8a009aece1474446b437a3c674db6', 'build_date': '2023-02-24T18:58:37.352296474Z', 'build_snapshot': False, 'lucene_version': '9.5.0', 'minimum_wire_compatibility_version': '7.10.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'The OpenSearch Project: https://opensearch.org/'}\n",
      "2023-09-05 21:24:42,605 - src.logger - INFO - intfloat-e5-small-v2-index exists\n",
      "2023-09-05 21:24:42,692 - src.logger - INFO - deleted intfloat-e5-small-v2-index because it already existed\n",
      "2023-09-05 21:24:42,693 - src.logger - INFO - Now creating intfloat-e5-small-v2-index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing amazon_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:24:51,433 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:24:51,434 - src.logger - INFO - first doc has 282140 chars\n",
      "2023-09-05 21:24:51,434 - src.logger - INFO - # of sub-docs from all 1 docs is 288\n",
      "100%|██████████| 288/288 [00:02<00:00, 118.75it/s]\n",
      "2023-09-05 21:25:19,020 - src.logger - INFO - Done\n",
      "2023-09-05 21:25:19,036 - src.logger - INFO - [{'epoch': '1693963519', 'timestamp': '01:25:19', 'count': '288'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing amazon_10k_2022.pdf to OpenSearch\n",
      "Writing google_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:25:24,013 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:25:24,013 - src.logger - INFO - first doc has 334124 chars\n",
      "2023-09-05 21:25:24,013 - src.logger - INFO - # of sub-docs from all 1 docs is 341\n",
      "100%|██████████| 300/300 [00:02<00:00, 141.61it/s]\n",
      "2023-09-05 21:25:50,435 - src.logger - INFO - Done\n",
      "2023-09-05 21:25:50,455 - src.logger - INFO - [{'epoch': '1693963550', 'timestamp': '01:25:50', 'count': '588'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing google_10k_2022.pdf to OpenSearch\n",
      "Writing meta_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:26:03,268 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:26:03,269 - src.logger - INFO - first doc has 490502 chars\n",
      "2023-09-05 21:26:03,269 - src.logger - INFO - # of sub-docs from all 1 docs is 540\n",
      "100%|██████████| 300/300 [00:02<00:00, 146.72it/s]\n",
      "2023-09-05 21:26:28,651 - src.logger - INFO - Done\n",
      "2023-09-05 21:26:28,678 - src.logger - INFO - [{'epoch': '1693963588', 'timestamp': '01:26:28', 'count': '888'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing meta_10k_2022.pdf to OpenSearch\n",
      "Writing tesla_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:26:54,534 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:26:54,534 - src.logger - INFO - first doc has 868975 chars\n",
      "2023-09-05 21:26:54,534 - src.logger - INFO - # of sub-docs from all 1 docs is 926\n",
      "100%|██████████| 300/300 [00:02<00:00, 147.41it/s]\n",
      "2023-09-05 21:27:17,867 - src.logger - INFO - Done\n",
      "2023-09-05 21:27:17,916 - src.logger - INFO - [{'epoch': '1693963637', 'timestamp': '01:27:17', 'count': '1188'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing tesla_10k_2022.pdf to OpenSearch\n",
      "Writing apple_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:27:22,353 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:27:22,353 - src.logger - INFO - first doc has 287558 chars\n",
      "2023-09-05 21:27:22,353 - src.logger - INFO - # of sub-docs from all 1 docs is 311\n",
      "100%|██████████| 300/300 [00:02<00:00, 121.82it/s]\n",
      "2023-09-05 21:27:50,856 - src.logger - INFO - Done\n",
      "2023-09-05 21:27:50,872 - src.logger - INFO - [{'epoch': '1693963670', 'timestamp': '01:27:50', 'count': '1488'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing apple_10k_2022.pdf to OpenSearch\n"
     ]
    }
   ],
   "source": [
    "model_id='intfloat/e5-small-v2' # this model needs \"passge\" and \"query\" prepended to the text\n",
    "path_pdfs = get_all_data_paths()\n",
    "osc = OpenSearchClient(model_id=model_id)\n",
    "osc.create_index(overwrite=True)\n",
    "for path_pdf in path_pdfs:\n",
    "    print(f'Writing {path_pdf.name} to OpenSearch')\n",
    "    write_embeddings(model_id, path_pdf, osc, prepend=True)\n",
    "    print(f'Finished writing {path_pdf.name} to OpenSearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:27:51,803 - src.logger - INFO - found 5 pdfs in /Users/meninderpurewal/My Drive/Mikey/Code/Retrieval/data\n",
      "2023-09-05 21:27:51,887 - src.logger - INFO - {'name': '87fee34ad386', 'cluster_name': 'docker-cluster', 'cluster_uuid': '-a_peNY5SsWnBbMYhkB_OA', 'version': {'distribution': 'opensearch', 'number': '2.6.0', 'build_type': 'tar', 'build_hash': '7203a5af21a8a009aece1474446b437a3c674db6', 'build_date': '2023-02-24T18:58:37.352296474Z', 'build_snapshot': False, 'lucene_version': '9.5.0', 'minimum_wire_compatibility_version': '7.10.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'The OpenSearch Project: https://opensearch.org/'}\n",
      "2023-09-05 21:27:51,914 - src.logger - INFO - thenlper-gte-small-index exists\n",
      "2023-09-05 21:27:52,010 - src.logger - INFO - deleted thenlper-gte-small-index because it already existed\n",
      "2023-09-05 21:27:52,011 - src.logger - INFO - Now creating thenlper-gte-small-index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing amazon_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:28:00,102 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:28:00,102 - src.logger - INFO - first doc has 282140 chars\n",
      "2023-09-05 21:28:00,102 - src.logger - INFO - # of sub-docs from all 1 docs is 288\n",
      "100%|██████████| 288/288 [00:02<00:00, 120.53it/s]\n",
      "2023-09-05 21:28:27,604 - src.logger - INFO - Done\n",
      "2023-09-05 21:28:27,630 - src.logger - INFO - [{'epoch': '1693963707', 'timestamp': '01:28:27', 'count': '288'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing amazon_10k_2022.pdf to OpenSearch\n",
      "Writing google_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:28:32,811 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:28:32,811 - src.logger - INFO - first doc has 334124 chars\n",
      "2023-09-05 21:28:32,812 - src.logger - INFO - # of sub-docs from all 1 docs is 341\n",
      "100%|██████████| 300/300 [00:02<00:00, 128.82it/s]\n",
      "2023-09-05 21:28:58,898 - src.logger - INFO - Done\n",
      "2023-09-05 21:28:58,937 - src.logger - INFO - [{'epoch': '1693963738', 'timestamp': '01:28:58', 'count': '588'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing google_10k_2022.pdf to OpenSearch\n",
      "Writing meta_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:29:11,485 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:29:11,485 - src.logger - INFO - first doc has 490502 chars\n",
      "2023-09-05 21:29:11,485 - src.logger - INFO - # of sub-docs from all 1 docs is 540\n",
      "100%|██████████| 300/300 [00:02<00:00, 123.41it/s]\n",
      "2023-09-05 21:29:36,853 - src.logger - INFO - Done\n",
      "2023-09-05 21:29:36,868 - src.logger - INFO - [{'epoch': '1693963776', 'timestamp': '01:29:36', 'count': '888'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing meta_10k_2022.pdf to OpenSearch\n",
      "Writing tesla_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:30:02,765 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:30:02,765 - src.logger - INFO - first doc has 868975 chars\n",
      "2023-09-05 21:30:02,765 - src.logger - INFO - # of sub-docs from all 1 docs is 926\n",
      "100%|██████████| 300/300 [00:02<00:00, 114.83it/s]\n",
      "2023-09-05 21:30:25,919 - src.logger - INFO - Done\n",
      "2023-09-05 21:30:25,932 - src.logger - INFO - [{'epoch': '1693963825', 'timestamp': '01:30:25', 'count': '1188'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing tesla_10k_2022.pdf to OpenSearch\n",
      "Writing apple_10k_2022.pdf to OpenSearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:30:30,600 - src.logger - INFO - 1 doc inputted\n",
      "2023-09-05 21:30:30,601 - src.logger - INFO - first doc has 287558 chars\n",
      "2023-09-05 21:30:30,601 - src.logger - INFO - # of sub-docs from all 1 docs is 311\n",
      "100%|██████████| 300/300 [00:02<00:00, 123.26it/s]\n",
      "2023-09-05 21:30:58,798 - src.logger - INFO - Done\n",
      "2023-09-05 21:30:58,830 - src.logger - INFO - [{'epoch': '1693963858', 'timestamp': '01:30:58', 'count': '1488'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing apple_10k_2022.pdf to OpenSearch\n"
     ]
    }
   ],
   "source": [
    "model_id='thenlper/gte-small'\n",
    "path_pdfs = get_all_data_paths()\n",
    "osc = OpenSearchClient(model_id=model_id)\n",
    "osc.create_index(overwrite=True)\n",
    "for path_pdf in path_pdfs:\n",
    "    print(f'Writing {path_pdf.name} to OpenSearch')\n",
    "    write_embeddings(model_id, path_pdf, osc, prepend=False)\n",
    "    print(f'Finished writing {path_pdf.name} to OpenSearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.39453125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate size of db\n",
    "# docs * sub*docs * vector size * 4 bytes * 2 models\n",
    "5 * 300 * 384 * 4 * 2 / 1024 / 1024 # in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf2",
   "language": "python",
   "name": "hf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
